---
title: "Main Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyr)
library(readr)
library(sf)
library(ggplot2)
library(rgdal)
library(broom)
library(tidytext)
library(ggwordcloud)
library(plotly)
```


# Sensor Data

## Import
```{r}
# Solved the datetime problem, just change class using other functions, not readr

MobileSensorReadings <- read_csv("DC5-Data/Sensor Data and Maps/MobileSensorReadings.csv") %>% 
  mutate(time = as.POSIXct(Timestamp)) %>% select(-Timestamp)

StaticSensorLocations <- read_csv("DC5-Data/Sensor Data and Maps/StaticSensorLocations.csv")

StaticSensorReadings <- read_csv("DC5-Data/Sensor Data and Maps/StaticSensorReadings.csv") %>% 
  mutate(time = as.POSIXct(Timestamp)) %>% select(-Timestamp)
```

```{r}
StHimark <- st_read(
  "DC5-Data/Sensor Data and Maps/StHimarkNeighborhoodShapefiles/StHimark.shp")
```

## Shapefile 

```{r}
map <- ggplot() + 
  geom_sf(data = StHimark, size = 0.25, color = "white", fill = "#69b3a2") + 
  ggtitle("Boundary Plot") + 
  coord_sf() +
  theme_void() 
# +
#   geom_point(data = StaticSensorLocations, aes(x = Long, y = Lat))
```

this one has neighbourhoods

```{r}
my_spdf <- readOGR(
  dsn= "DC5-Data/Sensor Data and Maps/StHimarkNeighborhoodShapefiles/",
  layer="StHimark",
  verbose=FALSE)

spdf_fortified <- tidy(my_spdf)
# Plot it
map2 <- ggplot() +
  geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group),
               fill="#69b3a2", color="white") +
  theme_void()
```

ask about extensions and shapefile, whether we can just use the shapefile itself 


## Sensor 

### Mobile

```{r}
MobileSensorReadings_by_min <- MobileSensorReadings %>%
  group_by(time) %>% mutate(min_Value = sum(Value)) %>% distinct(time, .keep_all=T)%>%
  select(time, min_Value)
max(MobileSensorReadings_by_min$min_Value) # 2020-04-09 02:43:25	
ggplot(MobileSensorReadings_by_min, aes(x=time, y=min_Value)) + geom_line()
```

By location

```{r}
# map + geom_point(data = MobileSensorReadings, aes(x=Long, y=Lat))
ggplot() + geom_point(data = MobileSensorReadings[1:2000,], aes(x=Long, y=Lat))
MobileSensorReadings_byloc <- MobileSensorReadings%>%
  group_by(Long, Lat, time) %>% mutate(min_Value = sum(Value))

fig <- MobileSensorReadings_byloc %>%
  plot_ly(x = ~Long, y = ~Lat, frame = ~time, size = ~Value, type = 'scatter', mode = 'markers', showlegend = T) #%>%
  # layout(xaxis = list(type = "log"))
fig
```



### Static

```{r}

```

# Text Analysis

```{r}
#Reading in the data
YInt_data <- read_csv("YInt.csv")
```

```{r}
#Tidying the data

data(stop_words)
#Goal: I would like to be able to use token = "tweets" in order to preserve # and @ (which are important in understanding tweeting patterns). I don't understand the error message that comes up when I do that, though
YInt_word <- YInt_data %>%
  unnest_tokens(word, message) %>% 
  anti_join(stop_words)

YInt_word %>% 
  count(word, sort = TRUE)
```

```{r}
#There was something about a missing dog?
YInt_word %>% filter(str_detect(word, "missing"))
```

```{r}
#Generating a word cloud from the most frequent words

wordclouddata<- YInt_word %>% 
  #group_by(location) %>% 
  count(word, sort = TRUE) %>% 
  head(100)
#glimpse(wordclouddata)

set.seed(53)
ggplot(wordclouddata, aes(label = word, size = n)) +
  geom_text_wordcloud() #+
  #scale_size_area(max_size = 10) +
  #theme_minimal()
```


Goals from group meeting:
- word cloud for each location (preferably overlaid on map)
- missing dog (dachschund)
- anything interesting in messages


