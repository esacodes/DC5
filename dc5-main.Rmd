---
title: "Main Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyr)
library(readr)
library(sf)
library(ggplot2)
library(rgdal)
library(broom)
library(tidytext)
library(ggwordcloud)

```


# Sensor Data

## Import
```{r}
# Solved the datetime problem, just change class using other functions, not readr

MobileSensorReadings <- read_csv("DC5-Data/Sensor Data and Maps/MobileSensorReadings.csv") %>% 
  mutate(time = as.POSIXct(Timestamp)) %>% select(-Timestamp)

StaticSensorLocations <- read_csv("DC5-Data/Sensor Data and Maps/StaticSensorLocations.csv")

StaticSensorReadings <- read_csv("DC5-Data/Sensor Data and Maps/StaticSensorReadings.csv") %>% 
  mutate(time = as.POSIXct(Timestamp)) %>% select(-Timestamp)
```

```{r}
StHimark <- st_read(
  "DC5-Data/Sensor Data and Maps/StHimarkNeighborhoodShapefiles/StHimark.shp")
```


## Sensor 



## Shapefile 

```{r}
ggplot() + 
  geom_sf(data = StHimark, size = 0.25, color = "white", fill = "#69b3a2") + 
  ggtitle("Boundary Plot") + 
  coord_sf() +
  theme_void()
```

this one has neighbourhoods

```{r}
# my_spdf <- readOGR( 
#   dsn= "DC5-Data/Sensor Data and Maps/StHimarkNeighborhoodShapefiles/", 
#   layer="StHimark",
#   verbose=FALSE)
# 
# spdf_fortified <- tidy(my_spdf)
# # Plot it
# ggplot() +
#   geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group),
#                fill="#69b3a2", color="white") +
#   theme_void()
```

ask about extensions and shapefile, whether we can just use the shapefile itself 

# Text Analysis

```{r}
#Reading in the data
YInt_data <- read_csv("YInt.csv")
```

```{r}
#Tidying the data

data(stop_words)
#Goal: I would like to be able to use token = "tweets" in order to preserve # and @ (which are important in understanding tweeting patterns). I don't understand the error message that comes up when I do that, though
YInt_word <- YInt_data %>%
  unnest_tokens(word, message) %>% 
  anti_join(stop_words)

YInt_word %>% 
  count(word, sort = TRUE)
```

```{r}
#There was something about a missing dog?
YInt_word %>% filter(str_detect(word, "missing"))
```

```{r}
#Generating a word cloud from the most frequent words

wordclouddata<- YInt_word %>% 
  #group_by(location) %>% 
  count(word, sort = TRUE) %>% 
  head(100)
#glimpse(wordclouddata)

set.seed(53)
ggplot(wordclouddata, aes(label = word, size = n)) +
  geom_text_wordcloud() #+
  #scale_size_area(max_size = 10) +
  #theme_minimal()
```


Goals from group meeting:
- word cloud for each location (preferably overlaid on map)
- missing dog (dachschund)
- anything interesting in messages


